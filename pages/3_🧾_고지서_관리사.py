import streamlit as st
from openai import OpenAI
import base64

st.title("ğŸ§¾ ê³ ì§€ì„œ ê´€ë¦¬ ì±—ë´‡")
st.write("ê³ ì§€ì„œë¥¼ ì´¬ì˜í•˜ê±°ë‚˜ ì§ˆë¬¸ì„ ì…ë ¥í•´ ë³´ì„¸ìš”!")

client = st.session_state.get('openai_client', None)


# -------------------------------
# ë©”ì‹œì§€ ë Œë”ë§ í•¨ìˆ˜
# -------------------------------
def show_message(msg):
    st.chat_message(msg["role"]).write(msg["content"])


# -------------------------------
# ì„¸ì…˜ ì´ˆê¸°í™”
# -------------------------------
if "bill_messages" not in st.session_state:
    st.session_state.bill_messages = [
        {
            "role": "system",
            "content": (
                "ë„ˆëŠ” 1ì¸ ê°€êµ¬ ê³ ì§€ì„œ ë¶„ì„ ì „ë¬¸ê°€ì•¼. "
                "ì‚¬ì§„ ì† ê³ ì§€ì„œë¥¼ ì½ê³  OCRì„ ìˆ˜í–‰í•œ ë’¤, "
                "í•­ëª©ë³„ ìš”ê¸ˆí‘œë¥¼ ìš”ì•½í•˜ê³ , ì¦ê°€/ê°ì†Œ ì›ì¸ì„ ë¶„ì„í•˜ê³ , "
                "1ì¸ ê°€êµ¬ì—ê²Œ ë§ëŠ” ì ˆì•½ íŒì„ ì œê³µí•´."
                "ë˜ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë§ëŠ” íŒì„ ì œê³µí•´."
            )
        }
    ]


# -------------------------------
# ê³ ì§€ì„œ ì´ë¯¸ì§€ ì…ë ¥
# -------------------------------
image = st.camera_input("ğŸ“¸ ê³ ì§€ì„œë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì´¬ì˜í•˜ì„¸ìš”")


# -------------------------------
# ì±„íŒ… ê¸°ë¡ ë Œë”ë§
# -------------------------------
for msg in st.session_state.bill_messages:
    # system ë©”ì‹œì§€ëŠ” ì¶œë ¥í•˜ì§€ ì•ŠìŒ
    if msg["role"] != "system":
        show_message(msg)


# -------------------------------
# ì‚¬ìš©ìì˜ í…ìŠ¤íŠ¸ ì…ë ¥
# -------------------------------
if prompt := st.chat_input("ì—¬ê¸°ì— ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    user_msg = {"role": "user", "content": prompt}
    show_message(user_msg)
    st.session_state.bill_messages.append(user_msg)

    # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ base64 ë³€í™˜ í›„ inputì— í¬í•¨
    content_list = [{"type": "input_text", "text": prompt}]

    if image:
        img_b64 = base64.b64encode(image.getvalue()).decode()
        content_list.append({
            "type": "input_image",
            "image_url": f"data:image/jpeg;base64,{img_b64}"
        })

    # -------------------------------
    # Responses API í˜¸ì¶œ
    # -------------------------------
    response = client.responses.create(
        model="gpt-4.1",
        input=[
            *[
                # ê¸°ì¡´ ë©”ì‹œì§€ ë°˜ì˜
                {"role": msg["role"], "content": msg["content"]}
                for msg in st.session_state.bill_messages
                if msg["role"] != "assistant"  # assistant ì¤‘ë³µ í”„ë¡¬í”„íŠ¸ ë°©ì§€
            ],
            {"role": "user", "content": content_list},
        ]
    )

    assistant_reply = response.output_text

    # assistant ë©”ì‹œì§€ í‘œì‹œ ë° ì €ì¥
    assistant_msg = {"role": "assistant", "content": assistant_reply}
    show_message(assistant_msg)
    st.session_state.bill_messages.append(assistant_msg)